{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras import backend as K \n",
    "from keras.engine.training import Model\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout, Activation, Flatten\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.790</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.588</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.404</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.172</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dates  Year  Month  Day    Hours  Precipitation  Temperature  Outflow\n",
       "0  10/1/1980  1980     10    1  0:00:00            0.0      102.992      5.0\n",
       "1  10/1/1980  1980     10    1  1:00:00            0.0       97.790      5.0\n",
       "2  10/1/1980  1980     10    1  2:00:00            0.0       92.588      5.0\n",
       "3  10/1/1980  1980     10    1  3:00:00            0.0       87.404      5.0\n",
       "4  10/1/1980  1980     10    1  4:00:00            0.0       85.172      5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('../Sub0-RAW.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train and label column\n",
    "train_cols = [\"Outflow\"]\n",
    "label_cols = [\"Outflow(t+1)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the columns\n",
    "new_df = df.filter(train_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max scalr normalizing\n",
    "xtrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "xtest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to shift the time_series data for getting labels\n",
    "def lag_seq(df, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        df['Outflow(t+%d)' %(i+1)] = new_df['Outflow'].shift(-(i+1))\n",
    "    return df\n",
    "\n",
    "# building timeseries data with given timesteps\n",
    "def timeseries(X, Y, Y_actual, time_steps, out_steps):\n",
    "    input_size_0 = X.shape[0] - time_steps\n",
    "    input_size_1 = X.shape[1]\n",
    "    X_values = np.zeros((input_size_0, time_steps, input_size_1))\n",
    "    Y_values = np.zeros((input_size_0,))\n",
    "    Y_values_actual = np.zeros((input_size_0,))\n",
    "    \n",
    "    for i in tqdm_notebook(range(input_size_0)):\n",
    "        X_values[i] = X[i:time_steps+i]\n",
    "        Y_values[i] = Y[time_steps+i-1, 0]\n",
    "        Y_values_actual[i] = Y_actual[time_steps+i-1, 0]\n",
    "        \n",
    "    print(\"length of time-series i/o\",X_values.shape,Y_values.shape)\n",
    "    return X_values, Y_values, Y_values_actual\n",
    "\n",
    "#getting data ready for training the model\n",
    "def data_processing(lag_df):\n",
    "    #Splitting training and test data\n",
    "    df_train, df_test = train_test_split(lag_df, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "    x_train = df_train.loc[:,train_cols].values\n",
    "    y_train = df_train.loc[:,label_cols].values\n",
    "    x_test = df_test.loc[:,train_cols].values\n",
    "    y_test = df_test.loc[:,label_cols].values    \n",
    "   \n",
    "    #Normalizing training data\n",
    "    x_train_nor = xtrain_min_max_scaler.fit_transform(x_train)\n",
    "    y_train_nor = ytrain_min_max_scaler.fit_transform(y_train)\n",
    "\n",
    "    # Normalizing test data\n",
    "    x_test_nor = xtest_min_max_scaler.fit_transform(x_test)\n",
    "    y_test_nor = ytest_min_max_scaler.fit_transform(y_test)\n",
    "    \n",
    "    # Saving actual train and test y_label\n",
    "    y_train_actual = y_train\n",
    "    y_test_actual = y_test\n",
    "    \n",
    "    return x_train_nor, y_train_nor, y_train_actual, x_test_nor, y_test_nor, y_test_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling function to create lag dataframe\n",
    "lag_df = lag_seq(new_df, 1)\n",
    "lag_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5f11c6e0124afa97d32e8b3e005b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148416, 18, 3) (148416,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce2af63c4934698988634a7fc175a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37091.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37091, 18, 3) (37091,)\n"
     ]
    }
   ],
   "source": [
    "#Building timeseries\n",
    "x_train_nor, y_train_nor, y_train_actual, x_test_nor, y_test_nor, y_test_actual = data_processing(lag_df)\n",
    "X_Train, Y_Train, Y_train_actual = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=18, out_steps=1)\n",
    "X_Test, Y_Test, Y_test_actual = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=18, out_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build Model\n",
    "def make_model(X_Train):\n",
    "    input_layer = Input(shape=(X_Train.shape[1], X_Train.shape[2]))\n",
    "\n",
    "    lstm1 = LSTM(units=16, return_sequences=True)(input_layer)\n",
    "    dropout1 = Dropout(0.2)(lstm1)\n",
    "    lstm2 = LSTM(units=32, return_sequences=True)(dropout1)\n",
    "    dropout2 = Dropout(0.2)(lstm2)\n",
    "    lstm3 = LSTM(units=64)(dropout2)\n",
    "    dropout3 = Dropout(0.2)(lstm3)\n",
    "\n",
    "    dense1 = Dense(128, activation='relu')(dropout3)\n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    output_layer = Dense(1, activation='linear')(dense2)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 60s 13ms/step - loss: 1.3665e-04 - val_loss: 9.5106e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 73s 16ms/step - loss: 5.2869e-05 - val_loss: 3.2244e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 4.1892e-05 - val_loss: 1.5722e-04\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 3.5962e-05 - val_loss: 2.0481e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 76s 16ms/step - loss: 2.6742e-05 - val_loss: 7.4602e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 2.8924e-05 - val_loss: 1.7974e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 2.4621e-05 - val_loss: 1.2770e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 81s 17ms/step - loss: 2.2133e-05 - val_loss: 2.7484e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 73s 16ms/step - loss: 2.2675e-05 - val_loss: 2.5453e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 2.1258e-05 - val_loss: 9.3243e-06\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1612035066.7095242\n",
      "Completing time: 1612035841.837529\n",
      "It took -12.91880007982254 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "mse_for_iter = []\n",
    "train_loss_over_epoch = []\n",
    "val_loss_over_epoch = []\n",
    "\n",
    "def run_iteration(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model = make_model(X_Train)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model.fit(X_Train, Y_Train, epochs=epochs,\n",
    "                       validation_data=(X_Test, Y_Test))\n",
    "        train_loss_over_epoch.append(history.history['loss'])\n",
    "        val_loss_over_epoch.append(history.history['val_loss'])\n",
    "        predicted_y_values = model.predict(X_Test)\n",
    "        predicted_y_values_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values)\n",
    "        mse_for_iter.append(mean_squared_error(predicted_y_values_unnor, Y_test_actual))\n",
    "               \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values, predicted_y_values_unnor, model\n",
    "\n",
    "predicted_y_values, predicted_y_values_unnor, model = run_iteration(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for X_Train values which has to be used to predict another day output\n",
    "y_train_predict = model.predict(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c173272694824b28aa816a3ba6746c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148415.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148415, 19, 3) (148415,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81278249b5784c9ea383732534a2552e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37090.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37090, 19, 3) (37090,)\n"
     ]
    }
   ],
   "source": [
    "#for model2\n",
    "#Building timeseries\n",
    "X_Train1, Y_Train1, Y_train_actual1 = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=19, out_steps=1)\n",
    "X_Test1, Y_Test1, Y_test_actual1 = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=19, out_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing last value of each timeseries data with the predicted value\n",
    "len_data = len(X_Train1)\n",
    "for i in range (len_data):\n",
    "    X_Train1[i][18] = y_train_predict[i]\n",
    "len_data_test = len(X_Test1)\n",
    "for i in range (len_data_test):\n",
    "    X_Test1[i][18] = predicted_y_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 118s 26ms/step - loss: 1.6441e-04 - val_loss: 7.3106e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 106s 23ms/step - loss: 7.2694e-05 - val_loss: 4.8472e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 108s 23ms/step - loss: 5.3962e-05 - val_loss: 4.9655e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 116s 25ms/step - loss: 4.4520e-05 - val_loss: 4.2064e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 99s 21ms/step - loss: 3.7278e-05 - val_loss: 4.1803e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 85s 18ms/step - loss: 3.4295e-05 - val_loss: 2.9837e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 85s 18ms/step - loss: 3.2741e-05 - val_loss: 1.1843e-04\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 85s 18ms/step - loss: 3.2770e-05 - val_loss: 6.3373e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 85s 18ms/step - loss: 2.8717e-05 - val_loss: 3.3131e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 85s 18ms/step - loss: 2.8085e-05 - val_loss: 2.2828e-05\n",
      "Iteration: 2\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 86s 19ms/step - loss: 1.7191e-04 - val_loss: 8.8369e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 86s 18ms/step - loss: 7.3110e-05 - val_loss: 6.2951e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 86s 18ms/step - loss: 5.1154e-05 - val_loss: 4.1028e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 85s 18ms/step - loss: 4.8308e-05 - val_loss: 1.3108e-04\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 86s 18ms/step - loss: 3.5408e-05 - val_loss: 3.1481e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 86s 18ms/step - loss: 3.2724e-05 - val_loss: 3.5908e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 86s 18ms/step - loss: 2.9111e-05 - val_loss: 4.5998e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 2.6239e-05 - val_loss: 3.6715e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 2.4240e-05 - val_loss: 2.4703e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 2.1997e-05 - val_loss: 3.6182e-05\n",
      "Iteration: 3\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 1.6753e-04 - val_loss: 7.3159e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 7.1226e-05 - val_loss: 5.8902e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 5.2711e-05 - val_loss: 5.5118e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 4.5190e-05 - val_loss: 7.4542e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.9659e-05 - val_loss: 1.2177e-04\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.4892e-05 - val_loss: 2.3155e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 81s 18ms/step - loss: 3.5879e-05 - val_loss: 5.4790e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.2226e-05 - val_loss: 5.3038e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 3.0046e-05 - val_loss: 7.2961e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.0392e-05 - val_loss: 3.4146e-05\n",
      "Iteration: 4\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 1.4775e-04 - val_loss: 6.9703e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 6.3672e-05 - val_loss: 4.2460e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 5.0011e-05 - val_loss: 5.9481e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 4.0251e-05 - val_loss: 3.0945e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 3.7602e-05 - val_loss: 3.3646e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 3.4693e-05 - val_loss: 4.3323e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.2736e-05 - val_loss: 5.4091e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 2.8889e-05 - val_loss: 2.7592e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 2.6611e-05 - val_loss: 2.3828e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 2.5925e-05 - val_loss: 2.9036e-05\n",
      "Iteration: 5\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 1.5339e-04 - val_loss: 7.0178e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 7.1875e-05 - val_loss: 4.9058e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 5.3682e-05 - val_loss: 4.1385e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 4.4825e-05 - val_loss: 3.0779e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 3.5711e-05 - val_loss: 4.8814e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.4799e-05 - val_loss: 2.4692e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.6606e-05 - val_loss: 2.5414e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.1047e-05 - val_loss: 2.4275e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 2.8991e-05 - val_loss: 1.0279e-04\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 2.5830e-05 - val_loss: 2.4113e-05\n",
      "Iteration: 6\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 1.6938e-04 - val_loss: 7.4654e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 6.9297e-05 - val_loss: 5.2597e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 5.2875e-05 - val_loss: 4.3296e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 4.2134e-05 - val_loss: 3.9913e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 4.0579e-05 - val_loss: 3.3769e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.6643e-05 - val_loss: 3.2821e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.2320e-05 - val_loss: 4.1606e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 2.9888e-05 - val_loss: 3.7397e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.0326e-05 - val_loss: 2.2560e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 2.8087e-05 - val_loss: 2.4170e-05\n",
      "Iteration: 7\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 1.6605e-04 - val_loss: 7.6324e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 6.3082e-05 - val_loss: 4.5534e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 4.6345e-05 - val_loss: 8.8695e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 4.0285e-05 - val_loss: 3.6229e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.9217e-05 - val_loss: 3.2050e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.6294e-05 - val_loss: 3.9659e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.1207e-05 - val_loss: 3.3349e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.0909e-05 - val_loss: 3.1919e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 2.7820e-05 - val_loss: 2.4594e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 2.6323e-05 - val_loss: 3.7204e-05\n",
      "Iteration: 8\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 1.4657e-04 - val_loss: 9.8342e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 6.0082e-05 - val_loss: 2.0999e-04\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 5.2657e-05 - val_loss: 4.3438e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.9898e-05 - val_loss: 3.5023e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.9862e-05 - val_loss: 7.0454e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.4383e-05 - val_loss: 2.8428e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.4730e-05 - val_loss: 2.3304e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 2.9728e-05 - val_loss: 2.8152e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 2.6602e-05 - val_loss: 2.2154e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.0492e-05 - val_loss: 2.5513e-05\n",
      "Iteration: 9\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 1.5919e-04 - val_loss: 8.7897e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 6.3269e-05 - val_loss: 6.4804e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 5.2748e-05 - val_loss: 4.7171e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 4.0676e-05 - val_loss: 3.0609e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.9169e-05 - val_loss: 3.3291e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.4196e-05 - val_loss: 3.2833e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.4116e-05 - val_loss: 6.7604e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.1672e-05 - val_loss: 2.2448e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 2.8285e-05 - val_loss: 4.3188e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 80s 17ms/step - loss: 2.8546e-05 - val_loss: 1.9381e-05\n",
      "Iteration: 10\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 1.5625e-04 - val_loss: 1.1037e-04\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 6.4510e-05 - val_loss: 5.7821e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 5.1616e-05 - val_loss: 4.9362e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 4.7907e-05 - val_loss: 3.7254e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 3.8994e-05 - val_loss: 5.2007e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 79s 17ms/step - loss: 3.4732e-05 - val_loss: 3.3941e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.2690e-05 - val_loss: 1.4151e-04\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.1819e-05 - val_loss: 3.9829e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 3.1451e-05 - val_loss: 3.7364e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 77s 17ms/step - loss: 2.7498e-05 - val_loss: 3.5468e-05\n",
      "Iteration: 11\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 78s 17ms/step - loss: 1.4565e-04 - val_loss: 1.0531e-04\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 86s 19ms/step - loss: 6.3054e-05 - val_loss: 4.8260e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 5.6074e-05 - val_loss: 3.8853e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 4.2224e-05 - val_loss: 3.8089e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.6836e-05 - val_loss: 5.2078e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.3415e-05 - val_loss: 2.6782e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 87s 19ms/step - loss: 3.2228e-05 - val_loss: 7.0044e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.8203e-05 - val_loss: 1.8814e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 87s 19ms/step - loss: 2.8527e-05 - val_loss: 3.4268e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.6180e-05 - val_loss: 3.0038e-05\n",
      "Iteration: 12\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 1.6372e-04 - val_loss: 8.2232e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 6.5190e-05 - val_loss: 5.6008e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 87s 19ms/step - loss: 5.4094e-05 - val_loss: 3.0349e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 4.0654e-05 - val_loss: 5.9232e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.8502e-05 - val_loss: 5.2462e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.5402e-05 - val_loss: 3.2811e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 91s 20ms/step - loss: 3.2240e-05 - val_loss: 2.3701e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.0908e-05 - val_loss: 2.3596e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.1555e-05 - val_loss: 2.5799e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.7186e-05 - val_loss: 2.8198e-05\n",
      "Iteration: 13\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 1.5290e-04 - val_loss: 7.1662e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 6.9593e-05 - val_loss: 5.3021e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 4.9887e-05 - val_loss: 4.6415e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 4.6233e-05 - val_loss: 8.1516e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.6029e-05 - val_loss: 5.6451e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.3822e-05 - val_loss: 3.8477e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.1881e-05 - val_loss: 2.7388e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.1388e-05 - val_loss: 6.0377e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.5850e-05 - val_loss: 2.3056e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.7392e-05 - val_loss: 2.5828e-05\n",
      "Iteration: 14\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 89s 19ms/step - loss: 1.5261e-04 - val_loss: 7.6913e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 6.5615e-05 - val_loss: 1.7690e-04\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 5.6609e-05 - val_loss: 3.8849e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 4.3745e-05 - val_loss: 1.1801e-04\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 89s 19ms/step - loss: 3.8151e-05 - val_loss: 3.6460e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.7849e-05 - val_loss: 3.4938e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.1254e-05 - val_loss: 3.5385e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 3.2920e-05 - val_loss: 4.4760e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.7789e-05 - val_loss: 3.3364e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.6819e-05 - val_loss: 3.6225e-05\n",
      "Iteration: 15\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 89s 19ms/step - loss: 1.7403e-04 - val_loss: 9.6905e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 6.4564e-05 - val_loss: 1.9606e-04\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 5.1510e-05 - val_loss: 4.8744e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 4.1150e-05 - val_loss: 2.9311e-05\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638/4638 [==============================] - 81s 17ms/step - loss: 3.8312e-05 - val_loss: 3.9966e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 81s 18ms/step - loss: 3.4055e-05 - val_loss: 4.8090e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 81s 18ms/step - loss: 3.0324e-05 - val_loss: 2.7165e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 3.0141e-05 - val_loss: 2.8398e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 81s 18ms/step - loss: 2.8181e-05 - val_loss: 3.0593e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 2.6986e-05 - val_loss: 2.2499e-05\n",
      "Iteration: 16\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 83s 18ms/step - loss: 1.5861e-04 - val_loss: 1.0529e-04\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 6.7006e-05 - val_loss: 4.9431e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 4.6799e-05 - val_loss: 3.4033e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 4.0516e-05 - val_loss: 3.8637e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 3.7803e-05 - val_loss: 4.0287e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 3.7881e-05 - val_loss: 2.4450e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 82s 18ms/step - loss: 3.2455e-05 - val_loss: 3.1639e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 84s 18ms/step - loss: 3.5084e-05 - val_loss: 2.7415e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.6954e-05 - val_loss: 7.6114e-05\n",
      "Epoch 10/10\n",
      "1127/4638 [======>.......................] - ETA: 54s - loss: 2.1448e-05"
     ]
    }
   ],
   "source": [
    "mse_for_iter1 = []\n",
    "train_loss_over_epoch1 = []\n",
    "val_loss_over_epoch1 = []\n",
    "predicted_y_values1_unnors = []\n",
    "models = []\n",
    "\n",
    "def run_iteration_model_2(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model1 = make_model(X_Train1)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model1.fit(X_Train1, Y_Train1, epochs=epochs,\n",
    "                       validation_data=(X_Test1, Y_Test1))\n",
    "        train_loss_over_epoch1.append(history.history['loss'])\n",
    "        val_loss_over_epoch1.append(history.history['val_loss'])\n",
    "        predicted_y_values1 = model1.predict(X_Test1)\n",
    "        predicted_y_values1_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values1)\n",
    "        mse_for_iter1.append(mean_squared_error(predicted_y_values1_unnor, Y_test_actual1))\n",
    "        predicted_y_values1_unnors.append(predicted_y_values1_unnor)\n",
    "        models.append(model1)\n",
    "               \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values1, predicted_y_values1_unnor, model1\n",
    "\n",
    "predicted_y_values1, predicted_y_values1_unnor, model1 = run_iteration_model_2(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm_model2_3_features.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation():\n",
    "    #mean square error over iterations\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(mse_for_iter1)\n",
    "    plt.ylabel('mean squared error')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.savefig('mse.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "        \n",
    "    #plot train and validation loss over epochs for each iteration\n",
    "    fig, axs = plt.subplots(10, 2)\n",
    "    #axs.set_ylabel('loss')\n",
    "    #axs.set_xlabel('epoch')\n",
    "    fig.set_size_inches(18.5, 50)\n",
    "    for row in range(10):\n",
    "        for col in range(2):\n",
    "            index = 2*row + col #index to get loss from training loss and validation loss list\n",
    "            axs[row, col].plot(train_loss_over_epoch1[index])\n",
    "            axs[row, col].plot(val_loss_over_epoch1[index])\n",
    "            axs[row, col].set_title('Iteration(%d)' %(index+1))\n",
    "            axs[row, col].legend(['train', 'Val'], loc='upper left')            \n",
    "    plt.savefig('train_val_loss.png', bbox_inches='tight')\n",
    "    \n",
    "    #plot predicted value vs actual values from last iteration\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(predicted_y_values1_unnor, 'ro', alpha=0.8)\n",
    "    plt.plot(Y_test_actual1, 'bo', alpha=0.1)\n",
    "    plt.legend(['Predicted values', 'Actual values'], loc='upper right')\n",
    "    plt.ylabel('Outflow')\n",
    "    plt.xlabel('nth datapoint')\n",
    "    plt.savefig('predicted_values_visuals.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "#call plot_evaluation function\n",
    "plot_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_for_iter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(mse_for_iter1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
