{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras import backend as K \n",
    "from keras.engine.training import Model\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout, Activation, Flatten\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.790</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.588</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.404</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.172</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dates  Year  Month  Day    Hours  Precipitation  Temperature  Outflow\n",
       "0  10/1/1980  1980     10    1  0:00:00            0.0      102.992      5.0\n",
       "1  10/1/1980  1980     10    1  1:00:00            0.0       97.790      5.0\n",
       "2  10/1/1980  1980     10    1  2:00:00            0.0       92.588      5.0\n",
       "3  10/1/1980  1980     10    1  3:00:00            0.0       87.404      5.0\n",
       "4  10/1/1980  1980     10    1  4:00:00            0.0       85.172      5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Sub0-RAW.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [\"Precipitation\", \"Outflow\"]\n",
    "label_cols = [\"Outflow(t+1)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.filter(train_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max scalr normalizing\n",
    "xtrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "xtest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to shift the time_series data for getting labels\n",
    "def lag_seq(df, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        df['Outflow(t+%d)' %(i+1)] = new_df['Outflow'].shift(-(i+1))\n",
    "    return df\n",
    "\n",
    "# building timeseries data with given timesteps\n",
    "def timeseries(X, Y, Y_actual, time_steps, out_steps):\n",
    "    input_size_0 = X.shape[0] - time_steps\n",
    "    input_size_1 = X.shape[1]\n",
    "    X_values = np.zeros((input_size_0, time_steps, input_size_1))\n",
    "    Y_values = np.zeros((input_size_0,))\n",
    "    Y_values_actual = np.zeros((input_size_0,))\n",
    "    \n",
    "    for i in tqdm_notebook(range(input_size_0)):\n",
    "        X_values[i] = X[i:time_steps+i]\n",
    "        Y_values[i] = Y[time_steps+i-1, 0]\n",
    "        Y_values_actual[i] = Y_actual[time_steps+i-1, 0]\n",
    "        \n",
    "    print(\"length of time-series i/o\",X_values.shape,Y_values.shape)\n",
    "    return X_values, Y_values, Y_values_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling function to create lag dataframe\n",
    "lag_df = lag_seq(new_df, 1)\n",
    "lag_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting training and test data\n",
    "df_train, df_test = train_test_split(lag_df, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "x_train = df_train.loc[:,train_cols].values\n",
    "y_train = df_train.loc[:,label_cols].values\n",
    "x_test = df_test.loc[:,train_cols].values\n",
    "y_test = df_test.loc[:,label_cols].values    \n",
    "\n",
    "#Normalizing training data\n",
    "x_train_nor = xtrain_min_max_scaler.fit_transform(x_train)\n",
    "y_train_nor = ytrain_min_max_scaler.fit_transform(y_train)\n",
    "\n",
    "# Normalizing test data\n",
    "x_test_nor = xtest_min_max_scaler.fit_transform(x_test)\n",
    "y_test_nor = ytest_min_max_scaler.fit_transform(y_test)\n",
    "\n",
    "# Saving actual train and test y_label\n",
    "y_train_actual = y_train\n",
    "y_test_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mse for test set that are greater than threshold\n",
    "threshold = 250\n",
    "timesteps = 19\n",
    "test_values_above_thres = []\n",
    "test_labels_above_theres = []\n",
    "\n",
    "for i in range(timesteps, x_test.shape[0]):\n",
    "    if (y_test[i] > threshold):\n",
    "        test_values_above_thres.append(x_test[i-timesteps:i])\n",
    "        test_labels_above_theres.append(y_test[i]) \n",
    "        \n",
    "X_test_abv_thres = np.array(test_values_above_thres)\n",
    "Y_test_abv_thres = np.array(test_labels_above_theres)\n",
    "\n",
    "tsamples, ta, tb = X_test_abv_thres.shape\n",
    "x_test_for_normalization = X_test_abv_thres.reshape((tsamples,ta*tb)) # since normalization requires 2d array\n",
    "x_test_for_normalization.shape\n",
    "\n",
    "X_Test_abv_thres = xtest_min_max_scaler.fit_transform(x_test_for_normalization)\n",
    "Y_Test_abv_thres = ytest_min_max_scaler.fit_transform(Y_test_abv_thres)\n",
    "\n",
    "X_Test_abv_thres = X_Test_abv_thres.reshape((tsamples, ta, tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e64b09ba7934a4c9b89c2010967931d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148416, 18, 2) (148416,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c979fcda0474643b269c5faacddba8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37091.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37091, 18, 2) (37091,)\n"
     ]
    }
   ],
   "source": [
    "#Building timeseries\n",
    "X_Train, Y_Train, Y_train_actual = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=18, out_steps=1)\n",
    "X_Test, Y_Test, Y_test_actual = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=18, out_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build Model\n",
    "def make_model(X_Train):\n",
    "    input_layer = Input(shape=(X_Train.shape[1], X_Train.shape[2]))\n",
    "\n",
    "    lstm1 = LSTM(units=16, return_sequences=True)(input_layer)\n",
    "    dropout1 = Dropout(0.2)(lstm1)\n",
    "    lstm2 = LSTM(units=32, return_sequences=True)(dropout1)\n",
    "    dropout2 = Dropout(0.2)(lstm2)\n",
    "    lstm3 = LSTM(units=64)(dropout2)\n",
    "    dropout3 = Dropout(0.2)(lstm3)\n",
    "\n",
    "    dense1 = Dense(128, activation='relu')(dropout3)\n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    output_layer = Dense(1, activation='linear')(dense2)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 106s 23ms/step - loss: 1.3158e-04 - val_loss: 6.2737e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 102s 22ms/step - loss: 5.2062e-05 - val_loss: 3.0656e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 102s 22ms/step - loss: 4.6438e-05 - val_loss: 2.1333e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 102s 22ms/step - loss: 3.4380e-05 - val_loss: 1.0280e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 104s 23ms/step - loss: 2.9044e-05 - val_loss: 1.5776e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 105s 23ms/step - loss: 2.6909e-05 - val_loss: 1.1149e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 90s 19ms/step - loss: 2.3539e-05 - val_loss: 1.3931e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 102s 22ms/step - loss: 2.0779e-05 - val_loss: 1.8384e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 94s 20ms/step - loss: 2.1575e-05 - val_loss: 7.2694e-06\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 90s 19ms/step - loss: 2.1284e-05 - val_loss: 2.7695e-05\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1612916220.0308936\n",
      "Completing time: 1612917255.7291622\n",
      "It took -17.261637810866038 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "mse_for_iter = []\n",
    "train_loss_over_epoch = []\n",
    "val_loss_over_epoch = []\n",
    "\n",
    "def run_iteration(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model = make_model(X_Train)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model.fit(X_Train, Y_Train, epochs=epochs,\n",
    "                       validation_data=(X_Test, Y_Test))\n",
    "        train_loss_over_epoch.append(history.history['loss'])\n",
    "        val_loss_over_epoch.append(history.history['val_loss'])\n",
    "        predicted_y_values = model.predict(X_Test)\n",
    "        predicted_y_values_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values)\n",
    "        mse_for_iter.append(mean_squared_error(predicted_y_values_unnor, Y_test_actual))\n",
    "               \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values, predicted_y_values_unnor, model\n",
    "\n",
    "predicted_y_values, predicted_y_values_unnor, model = run_iteration(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for X_Train values which has to be used to predict another day output\n",
    "y_train_predict = model.predict(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0857b954c54cf49bf77509834a093b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148415.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148415, 19, 2) (148415,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b8dbcf9667f4a1f82f825ba6946e139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37090.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37090, 19, 2) (37090,)\n"
     ]
    }
   ],
   "source": [
    "#for model2\n",
    "#Building timeseries\n",
    "X_Train1, Y_Train1, Y_train_actual1 = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=19, out_steps=1)\n",
    "X_Test1, Y_Test1, Y_test_actual1 = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=19, out_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing last value of each timeseries data with the predicted value\n",
    "len_data = len(X_Train1)\n",
    "for i in range (len_data):\n",
    "    X_Train1[i][18] = y_train_predict[i]\n",
    "len_data_test = len(X_Test1)\n",
    "for i in range (len_data_test):\n",
    "    X_Test1[i][18] = predicted_y_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 139s 30ms/step - loss: 1.2009e-04 - val_loss: 5.0717e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 158s 34ms/step - loss: 6.9785e-05 - val_loss: 4.5620e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 164s 35ms/step - loss: 5.5200e-05 - val_loss: 3.8006e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 158s 34ms/step - loss: 4.5895e-05 - val_loss: 1.2281e-04\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 157s 34ms/step - loss: 3.8782e-05 - val_loss: 9.0273e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 185s 40ms/step - loss: 4.1053e-05 - val_loss: 2.8240e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 185s 40ms/step - loss: 3.4993e-05 - val_loss: 3.5266e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 172s 37ms/step - loss: 3.0804e-05 - val_loss: 2.6573e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 197s 43ms/step - loss: 3.0699e-05 - val_loss: 2.0639e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 202s 44ms/step - loss: 2.7955e-05 - val_loss: 2.9723e-05\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1612917290.3446064\n",
      "Completing time: 1612919035.8956645\n",
      "It took -29.092517634232838 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "mse_for_iter1 = []\n",
    "train_loss_over_epoch1 = []\n",
    "val_loss_over_epoch1 = []\n",
    "predicted_y_values1_unnors = []\n",
    "models = []\n",
    "\n",
    "def run_iteration_model_2(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model1 = make_model(X_Train1)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model1.fit(X_Train1, Y_Train1, epochs=epochs,\n",
    "                       validation_data=(X_Test1, Y_Test1))\n",
    "        train_loss_over_epoch1.append(history.history['loss'])\n",
    "        val_loss_over_epoch1.append(history.history['val_loss'])\n",
    "        predicted_y_values1 = model1.predict(X_Test1)\n",
    "        predicted_y_values1_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values1)\n",
    "        mse_for_iter1.append(mean_squared_error(predicted_y_values1_unnor, Y_test_actual1))\n",
    "        predicted_y_values1_unnors.append(predicted_y_values1_unnor)\n",
    "        models.append(model1)\n",
    "               \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values1, predicted_y_values1_unnor, model1\n",
    "\n",
    "predicted_y_values1, predicted_y_values1_unnor, model1 = run_iteration_model_2(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"lstm_model2_2_features_pre_flow.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299556.1393307635"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_test_abv_thres = model1.predict(X_Test_abv_thres)\n",
    "predicted_y_test_abv_thres_unnor = ytest_min_max_scaler.inverse_transform(predicted_y_test_abv_thres)\n",
    "mean_square_root_abv_thres = mean_squared_error(predicted_y_test_abv_thres, Y_test_abv_thres)\n",
    "mean_square_root_abv_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
