{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras import backend as K \n",
    "from keras.engine.training import Model\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout, Activation, Flatten\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.790</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.588</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.404</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.172</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dates  Year  Month  Day    Hours  Precipitation  Temperature  Outflow\n",
       "0  10/1/1980  1980     10    1  0:00:00            0.0      102.992      5.0\n",
       "1  10/1/1980  1980     10    1  1:00:00            0.0       97.790      5.0\n",
       "2  10/1/1980  1980     10    1  2:00:00            0.0       92.588      5.0\n",
       "3  10/1/1980  1980     10    1  3:00:00            0.0       87.404      5.0\n",
       "4  10/1/1980  1980     10    1  4:00:00            0.0       85.172      5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Sub0-RAW.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [\"Temperature\", \"Outflow\"]\n",
    "label_cols = [\"Outflow(t+1)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.filter(train_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max scalr normalizing\n",
    "xtrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "xtest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to shift the time_series data for getting labels\n",
    "def lag_seq(df, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        df['Outflow(t+%d)' %(i+1)] = new_df['Outflow'].shift(-(i+1))\n",
    "    return df\n",
    "\n",
    "# building timeseries data with given timesteps\n",
    "def timeseries(X, Y, Y_actual, time_steps, out_steps):\n",
    "    input_size_0 = X.shape[0] - time_steps\n",
    "    input_size_1 = X.shape[1]\n",
    "    X_values = np.zeros((input_size_0, time_steps, input_size_1))\n",
    "    Y_values = np.zeros((input_size_0,))\n",
    "    Y_values_actual = np.zeros((input_size_0,))\n",
    "    \n",
    "    for i in tqdm_notebook(range(input_size_0)):\n",
    "        X_values[i] = X[i:time_steps+i]\n",
    "        Y_values[i] = Y[time_steps+i-1, 0]\n",
    "        Y_values_actual[i] = Y_actual[time_steps+i-1, 0]\n",
    "        \n",
    "    print(\"length of time-series i/o\",X_values.shape,Y_values.shape)\n",
    "    return X_values, Y_values, Y_values_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling function to create lag dataframe\n",
    "lag_df = lag_seq(new_df, 1)\n",
    "lag_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting training and test data\n",
    "df_train, df_test = train_test_split(lag_df, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "x_train = df_train.loc[:,train_cols].values\n",
    "y_train = df_train.loc[:,label_cols].values\n",
    "x_test = df_test.loc[:,train_cols].values\n",
    "y_test = df_test.loc[:,label_cols].values    \n",
    "\n",
    "#Normalizing training data\n",
    "x_train_nor = xtrain_min_max_scaler.fit_transform(x_train)\n",
    "y_train_nor = ytrain_min_max_scaler.fit_transform(y_train)\n",
    "\n",
    "# Normalizing test data\n",
    "x_test_nor = xtest_min_max_scaler.fit_transform(x_test)\n",
    "y_test_nor = ytest_min_max_scaler.fit_transform(y_test)\n",
    "\n",
    "# Saving actual train and test y_label\n",
    "y_train_actual = y_train\n",
    "y_test_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mse for test set that are greater than threshold\n",
    "threshold = 250\n",
    "timesteps = 19\n",
    "test_values_above_thres = []\n",
    "test_labels_above_theres = []\n",
    "\n",
    "for i in range(timesteps, x_test.shape[0]):\n",
    "    if (y_test[i] > threshold):\n",
    "        test_values_above_thres.append(x_test[i-timesteps:i])\n",
    "        test_labels_above_theres.append(y_test[i]) \n",
    "        \n",
    "X_test_abv_thres = np.array(test_values_above_thres)\n",
    "Y_test_abv_thres = np.array(test_labels_above_theres)\n",
    "\n",
    "tsamples, ta, tb = X_test_abv_thres.shape\n",
    "x_test_for_normalization = X_test_abv_thres.reshape((tsamples,ta*tb)) # since normalization requires 2d array\n",
    "x_test_for_normalization.shape\n",
    "\n",
    "X_Test_abv_thres = xtest_min_max_scaler.fit_transform(x_test_for_normalization)\n",
    "Y_Test_abv_thres = ytest_min_max_scaler.fit_transform(Y_test_abv_thres)\n",
    "\n",
    "X_Test_abv_thres = X_Test_abv_thres.reshape((tsamples, ta, tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182b4faa701541a7ad5b3d3ae3ac08b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148416, 18, 2) (148416,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d177f8fd2a44c41b68d678addc51dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37091.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37091, 18, 2) (37091,)\n"
     ]
    }
   ],
   "source": [
    "#Building timeseries\n",
    "X_Train, Y_Train, Y_train_actual = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=18, out_steps=1)\n",
    "X_Test, Y_Test, Y_test_actual = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=18, out_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build Model\n",
    "def make_model(X_Train):\n",
    "    input_layer = Input(shape=(X_Train.shape[1], X_Train.shape[2]))\n",
    "\n",
    "    lstm1 = LSTM(units=16, return_sequences=True)(input_layer)\n",
    "    dropout1 = Dropout(0.2)(lstm1)\n",
    "    lstm2 = LSTM(units=32, return_sequences=True)(dropout1)\n",
    "    dropout2 = Dropout(0.2)(lstm2)\n",
    "    lstm3 = LSTM(units=64)(dropout2)\n",
    "    dropout3 = Dropout(0.2)(lstm3)\n",
    "\n",
    "    dense1 = Dense(128, activation='relu')(dropout3)\n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    output_layer = Dense(1, activation='linear')(dense2)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 131s 28ms/step - loss: 1.5191e-04 - val_loss: 9.3631e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 128s 28ms/step - loss: 5.8382e-05 - val_loss: 7.3871e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 124s 27ms/step - loss: 4.5923e-05 - val_loss: 1.7268e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 119s 26ms/step - loss: 3.5945e-05 - val_loss: 1.8957e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 128s 28ms/step - loss: 3.6692e-05 - val_loss: 2.0395e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 137s 30ms/step - loss: 2.8835e-05 - val_loss: 1.4477e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 138s 30ms/step - loss: 2.5063e-05 - val_loss: 2.6378e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 111s 24ms/step - loss: 2.4417e-05 - val_loss: 3.7459e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 88s 19ms/step - loss: 2.2759e-05 - val_loss: 2.9566e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 81s 17ms/step - loss: 1.7971e-05 - val_loss: 9.1049e-06\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1612918061.8711605\n",
      "Completing time: 1612919273.8536167\n",
      "It took -20.19970760345459 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "mse_for_iter = []\n",
    "train_loss_over_epoch = []\n",
    "val_loss_over_epoch = []\n",
    "\n",
    "def run_iteration(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model = make_model(X_Train)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model.fit(X_Train, Y_Train, epochs=epochs,\n",
    "                       validation_data=(X_Test, Y_Test))\n",
    "        train_loss_over_epoch.append(history.history['loss'])\n",
    "        val_loss_over_epoch.append(history.history['val_loss'])\n",
    "        predicted_y_values = model.predict(X_Test)\n",
    "        predicted_y_values_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values)\n",
    "        mse_for_iter.append(mean_squared_error(predicted_y_values_unnor, Y_test_actual))\n",
    "               \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values, predicted_y_values_unnor, model\n",
    "\n",
    "predicted_y_values, predicted_y_values_unnor, model = run_iteration(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for X_Train values which has to be used to predict another day output\n",
    "y_train_predict = model.predict(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4036b711c03145ba8fdf0d1508866514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148415.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148415, 19, 2) (148415,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb747cefd4b45d5bf59901ca2dc18d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37090.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37090, 19, 2) (37090,)\n"
     ]
    }
   ],
   "source": [
    "#for model2\n",
    "#Building timeseries\n",
    "X_Train1, Y_Train1, Y_train_actual1 = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=19, out_steps=1)\n",
    "X_Test1, Y_Test1, Y_test_actual1 = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=19, out_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing last value of each timeseries data with the predicted value\n",
    "len_data = len(X_Train1)\n",
    "for i in range (len_data):\n",
    "    X_Train1[i][18] = y_train_predict[i]\n",
    "len_data_test = len(X_Test1)\n",
    "for i in range (len_data_test):\n",
    "    X_Test1[i][18] = predicted_y_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 116s 25ms/step - loss: 1.6703e-04 - val_loss: 7.9826e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 114s 25ms/step - loss: 6.2258e-05 - val_loss: 5.6018e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 114s 25ms/step - loss: 4.9155e-05 - val_loss: 3.0077e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 117s 25ms/step - loss: 3.7727e-05 - val_loss: 2.9817e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 123s 27ms/step - loss: 3.4666e-05 - val_loss: 2.6386e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 114s 25ms/step - loss: 3.1274e-05 - val_loss: 2.5861e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 114s 25ms/step - loss: 3.1050e-05 - val_loss: 4.8698e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 114s 24ms/step - loss: 2.7904e-05 - val_loss: 2.6030e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 114s 24ms/step - loss: 2.7466e-05 - val_loss: 2.3854e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 114s 24ms/step - loss: 2.6799e-05 - val_loss: 2.7031e-05\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1612919302.9753597\n",
      "Completing time: 1612920471.4597702\n",
      "It took -19.474740175406136 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "mse_for_iter1 = []\n",
    "train_loss_over_epoch1 = []\n",
    "val_loss_over_epoch1 = []\n",
    "predicted_y_values1_unnors = []\n",
    "models = []\n",
    "\n",
    "def run_iteration_model_2(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model1 = make_model(X_Train1)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model1.fit(X_Train1, Y_Train1, epochs=epochs,\n",
    "                       validation_data=(X_Test1, Y_Test1))\n",
    "        train_loss_over_epoch1.append(history.history['loss'])\n",
    "        val_loss_over_epoch1.append(history.history['val_loss'])\n",
    "        predicted_y_values1 = model1.predict(X_Test1)\n",
    "        predicted_y_values1_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values1)\n",
    "        mse_for_iter1.append(mean_squared_error(predicted_y_values1_unnor, Y_test_actual1))\n",
    "        predicted_y_values1_unnors.append(predicted_y_values1_unnor)\n",
    "        models.append(model1)\n",
    "               \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values1, predicted_y_values1_unnor, model1\n",
    "\n",
    "predicted_y_values1, predicted_y_values1_unnor, model1 = run_iteration_model_2(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"lstm_model2_2_features_tem_flow.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299501.95728832815"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_test_abv_thres = model1.predict(X_Test_abv_thres)\n",
    "predicted_y_test_abv_thres_unnor = ytest_min_max_scaler.inverse_transform(predicted_y_test_abv_thres)\n",
    "mean_square_root_abv_thres = mean_squared_error(predicted_y_test_abv_thres, Y_test_abv_thres)\n",
    "mean_square_root_abv_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
