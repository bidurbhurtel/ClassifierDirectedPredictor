{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras import backend as K \n",
    "from keras.engine.training import Model\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout, Activation, Flatten\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.790</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.588</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.404</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.172</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dates  Year  Month  Day    Hours  Precipitation  Temperature  Outflow\n",
       "0  10/1/1980  1980     10    1  0:00:00            0.0      102.992      5.0\n",
       "1  10/1/1980  1980     10    1  1:00:00            0.0       97.790      5.0\n",
       "2  10/1/1980  1980     10    1  2:00:00            0.0       92.588      5.0\n",
       "3  10/1/1980  1980     10    1  3:00:00            0.0       87.404      5.0\n",
       "4  10/1/1980  1980     10    1  4:00:00            0.0       85.172      5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Sub0-RAW.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [\"Outflow\"]\n",
    "label_cols = [\"Outflow(t+1)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.filter(train_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max scalr normalizing\n",
    "xtrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "xtest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to shift the time_series data for getting labels\n",
    "def lag_seq(df, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        df['Outflow(t+%d)' %(i+1)] = new_df['Outflow'].shift(-(i+1))\n",
    "    return df\n",
    "\n",
    "# building timeseries data with given timesteps\n",
    "def timeseries(X, Y, Y_actual, time_steps, out_steps):\n",
    "    input_size_0 = X.shape[0] - time_steps\n",
    "    input_size_1 = X.shape[1]\n",
    "    X_values = np.zeros((input_size_0, time_steps, input_size_1))\n",
    "    Y_values = np.zeros((input_size_0,))\n",
    "    Y_values_actual = np.zeros((input_size_0,))\n",
    "    \n",
    "    for i in tqdm_notebook(range(input_size_0)):\n",
    "        X_values[i] = X[i:time_steps+i]\n",
    "        Y_values[i] = Y[time_steps+i-1, 0]\n",
    "        Y_values_actual[i] = Y_actual[time_steps+i-1, 0]\n",
    "        \n",
    "    print(\"length of time-series i/o\",X_values.shape,Y_values.shape)\n",
    "    return X_values, Y_values, Y_values_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling function to create lag dataframe\n",
    "lag_df = lag_seq(new_df, 1)\n",
    "lag_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting training and test data\n",
    "df_train, df_test = train_test_split(lag_df, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "x_train = df_train.loc[:,train_cols].values\n",
    "y_train = df_train.loc[:,label_cols].values\n",
    "x_test = df_test.loc[:,train_cols].values\n",
    "y_test = df_test.loc[:,label_cols].values    \n",
    "\n",
    "#Normalizing training data\n",
    "x_train_nor = xtrain_min_max_scaler.fit_transform(x_train)\n",
    "y_train_nor = ytrain_min_max_scaler.fit_transform(y_train)\n",
    "\n",
    "# Normalizing test data\n",
    "x_test_nor = xtest_min_max_scaler.fit_transform(x_test)\n",
    "y_test_nor = ytest_min_max_scaler.fit_transform(y_test)\n",
    "\n",
    "# Saving actual train and test y_label\n",
    "y_train_actual = y_train\n",
    "y_test_actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mse for test set that are greater than threshold\n",
    "threshold = 250\n",
    "timesteps = 19\n",
    "test_values_above_thres = []\n",
    "test_labels_above_theres = []\n",
    "\n",
    "for i in range(timesteps, x_test.shape[0]):\n",
    "    if (y_test[i] > threshold):\n",
    "        test_values_above_thres.append(x_test[i-timesteps:i])\n",
    "        test_labels_above_theres.append(y_test[i]) \n",
    "        \n",
    "X_test_abv_thres = np.array(test_values_above_thres)\n",
    "Y_test_abv_thres = np.array(test_labels_above_theres)\n",
    "\n",
    "tsamples, ta, tb = X_test_abv_thres.shape\n",
    "x_test_for_normalization = X_test_abv_thres.reshape((tsamples,ta*tb)) # since normalization requires 2d array\n",
    "x_test_for_normalization.shape\n",
    "\n",
    "X_Test_abv_thres = xtest_min_max_scaler.fit_transform(x_test_for_normalization)\n",
    "Y_Test_abv_thres = ytest_min_max_scaler.fit_transform(Y_test_abv_thres)\n",
    "\n",
    "X_Test_abv_thres = X_Test_abv_thres.reshape((tsamples, ta, tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8076afc94dc447e1a2a3c7306691300f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148416, 18, 1) (148416,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a59a962f6b472a990e3ec20dd39b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37091.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37091, 18, 1) (37091,)\n"
     ]
    }
   ],
   "source": [
    "#Building timeseries\n",
    "X_Train, Y_Train, Y_train_actual = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=18, out_steps=1)\n",
    "X_Test, Y_Test, Y_test_actual = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=18, out_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build Model\n",
    "def make_model(X_Train):\n",
    "    input_layer = Input(shape=(X_Train.shape[1], X_Train.shape[2]))\n",
    "\n",
    "    lstm1 = LSTM(units=16, return_sequences=True)(input_layer)\n",
    "    dropout1 = Dropout(0.2)(lstm1)\n",
    "    lstm2 = LSTM(units=32, return_sequences=True)(dropout1)\n",
    "    dropout2 = Dropout(0.2)(lstm2)\n",
    "    lstm3 = LSTM(units=64)(dropout2)\n",
    "    dropout3 = Dropout(0.2)(lstm3)\n",
    "\n",
    "    dense1 = Dense(128, activation='relu')(dropout3)\n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    output_layer = Dense(1, activation='linear')(dense2)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 94s 20ms/step - loss: 1.3020e-04 - val_loss: 5.8095e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 92s 20ms/step - loss: 5.8066e-05 - val_loss: 7.0812e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 92s 20ms/step - loss: 4.0508e-05 - val_loss: 2.4296e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 92s 20ms/step - loss: 3.6440e-05 - val_loss: 1.4293e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 93s 20ms/step - loss: 2.7989e-05 - val_loss: 1.7138e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 92s 20ms/step - loss: 2.8114e-05 - val_loss: 7.9775e-06\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 92s 20ms/step - loss: 2.6167e-05 - val_loss: 2.1373e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 94s 20ms/step - loss: 2.1988e-05 - val_loss: 1.2883e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 93s 20ms/step - loss: 2.1030e-05 - val_loss: 7.0056e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 93s 20ms/step - loss: 2.1901e-05 - val_loss: 3.0144e-05\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1612910623.1292362\n",
      "Completing time: 1612911571.425926\n",
      "It took -15.804944829146068 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "mse_for_iter = []\n",
    "train_loss_over_epoch = []\n",
    "val_loss_over_epoch = []\n",
    "\n",
    "def run_iteration(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model = make_model(X_Train)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model.fit(X_Train, Y_Train, epochs=epochs,\n",
    "                       validation_data=(X_Test, Y_Test))\n",
    "        train_loss_over_epoch.append(history.history['loss'])\n",
    "        val_loss_over_epoch.append(history.history['val_loss'])\n",
    "        predicted_y_values = model.predict(X_Test)\n",
    "        predicted_y_values_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values)\n",
    "        mse_for_iter.append(mean_squared_error(predicted_y_values_unnor, Y_test_actual))\n",
    "               \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values, predicted_y_values_unnor, model\n",
    "\n",
    "predicted_y_values, predicted_y_values_unnor, model = run_iteration(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for X_Train values which has to be used to predict another day output\n",
    "y_train_predict = model.predict(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca09e63bb56f4391b71b6cff5ce20786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148415.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148415, 19, 1) (148415,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb11c759786476c82c4abe9d723dfe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37090.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37090, 19, 1) (37090,)\n"
     ]
    }
   ],
   "source": [
    "#for model2\n",
    "#Building timeseries\n",
    "X_Train1, Y_Train1, Y_train_actual1 = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=19, out_steps=1)\n",
    "X_Test1, Y_Test1, Y_test_actual1 = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=19, out_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing last value of each timeseries data with the predicted value\n",
    "len_data = len(X_Train1)\n",
    "for i in range (len_data):\n",
    "    X_Train1[i][18] = y_train_predict[i]\n",
    "len_data_test = len(X_Test1)\n",
    "for i in range (len_data_test):\n",
    "    X_Test1[i][18] = predicted_y_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 142s 31ms/step - loss: 1.3011e-04 - val_loss: 8.1855e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 127s 27ms/step - loss: 6.3685e-05 - val_loss: 5.8879e-05\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 120s 26ms/step - loss: 4.9531e-05 - val_loss: 4.7921e-05\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 119s 26ms/step - loss: 4.0785e-05 - val_loss: 3.1315e-05\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 120s 26ms/step - loss: 3.9247e-05 - val_loss: 9.3654e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 154s 33ms/step - loss: 3.3442e-05 - val_loss: 5.4329e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 197s 42ms/step - loss: 3.0733e-05 - val_loss: 2.5436e-05\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 183s 40ms/step - loss: 2.9550e-05 - val_loss: 4.7865e-05\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 183s 39ms/step - loss: 2.9791e-05 - val_loss: 3.4463e-05\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 183s 39ms/step - loss: 2.7355e-05 - val_loss: 2.3558e-05\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1612911605.8418643\n",
      "Completing time: 1612913155.7390983\n",
      "It took -25.831620566050212 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "mse_for_iter1 = []\n",
    "train_loss_over_epoch1 = []\n",
    "val_loss_over_epoch1 = []\n",
    "predicted_y_values1_unnors = []\n",
    "models = []\n",
    "\n",
    "def run_iteration_model_2(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model1 = make_model(X_Train1)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model1.fit(X_Train1, Y_Train1, epochs=epochs,\n",
    "                       validation_data=(X_Test1, Y_Test1))\n",
    "        train_loss_over_epoch1.append(history.history['loss'])\n",
    "        val_loss_over_epoch1.append(history.history['val_loss'])\n",
    "        predicted_y_values1 = model1.predict(X_Test1)\n",
    "        predicted_y_values1_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values1)\n",
    "        mse_for_iter1.append(mean_squared_error(predicted_y_values1_unnor, Y_test_actual1))\n",
    "        predicted_y_values1_unnors.append(predicted_y_values1_unnor)\n",
    "        models.append(model1)\n",
    "               \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values1, predicted_y_values1_unnor, model1\n",
    "\n",
    "predicted_y_values1, predicted_y_values1_unnor, model1 = run_iteration_model_2(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"lstm_model2_1_feature.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299481.97138169414"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_test_abv_thres = model1.predict(X_Test_abv_thres)\n",
    "predicted_y_test_abv_thres_unnor = ytest_min_max_scaler.inverse_transform(predicted_y_test_abv_thres)\n",
    "mean_square_root_abv_thres = mean_squared_error(predicted_y_test_abv_thres, Y_test_abv_thres)\n",
    "mean_square_root_abv_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
