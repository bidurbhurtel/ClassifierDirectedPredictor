{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras import backend as K \n",
    "from keras.engine.training import Model\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout, Activation, Flatten\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.790</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.588</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.404</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.172</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dates  Year  Month  Day    Hours  Precipitation  Temperature  Outflow\n",
       "0  10/1/1980  1980     10    1  0:00:00            0.0      102.992      5.0\n",
       "1  10/1/1980  1980     10    1  1:00:00            0.0       97.790      5.0\n",
       "2  10/1/1980  1980     10    1  2:00:00            0.0       92.588      5.0\n",
       "3  10/1/1980  1980     10    1  3:00:00            0.0       87.404      5.0\n",
       "4  10/1/1980  1980     10    1  4:00:00            0.0       85.172      5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('../Sub0-RAW.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train and label column\n",
    "train_cols = [\"Precipitation\",\"Temperature\",\"Outflow\"]\n",
    "label_cols = [\"Outflow(t+1)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the columns\n",
    "new_df = df.filter(train_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['ExtremeOrNot'] = np.where(new_df['Outflow'] > 250, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outflow</th>\n",
       "      <th>ExtremeOrNot</th>\n",
       "      <th>Outflow(t+1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12782</th>\n",
       "      <td>0.044870</td>\n",
       "      <td>43.592</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12783</th>\n",
       "      <td>0.025426</td>\n",
       "      <td>43.466</td>\n",
       "      <td>363.0</td>\n",
       "      <td>1</td>\n",
       "      <td>364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12784</th>\n",
       "      <td>0.004487</td>\n",
       "      <td>45.266</td>\n",
       "      <td>364.0</td>\n",
       "      <td>1</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>0.008974</td>\n",
       "      <td>47.048</td>\n",
       "      <td>355.0</td>\n",
       "      <td>1</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>0.017948</td>\n",
       "      <td>48.848</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>0.013461</td>\n",
       "      <td>50.396</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12788</th>\n",
       "      <td>0.010470</td>\n",
       "      <td>51.944</td>\n",
       "      <td>335.0</td>\n",
       "      <td>1</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12789</th>\n",
       "      <td>0.113671</td>\n",
       "      <td>53.492</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12790</th>\n",
       "      <td>0.020939</td>\n",
       "      <td>53.690</td>\n",
       "      <td>368.0</td>\n",
       "      <td>1</td>\n",
       "      <td>384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12791</th>\n",
       "      <td>0.016452</td>\n",
       "      <td>53.888</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12792</th>\n",
       "      <td>0.013578</td>\n",
       "      <td>54.104</td>\n",
       "      <td>396.0</td>\n",
       "      <td>1</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12793</th>\n",
       "      <td>0.047522</td>\n",
       "      <td>52.862</td>\n",
       "      <td>407.0</td>\n",
       "      <td>1</td>\n",
       "      <td>424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12794</th>\n",
       "      <td>0.063815</td>\n",
       "      <td>51.602</td>\n",
       "      <td>424.0</td>\n",
       "      <td>1</td>\n",
       "      <td>449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12795</th>\n",
       "      <td>0.069246</td>\n",
       "      <td>50.360</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1</td>\n",
       "      <td>472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12796</th>\n",
       "      <td>0.043448</td>\n",
       "      <td>49.424</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1</td>\n",
       "      <td>483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12797</th>\n",
       "      <td>0.012220</td>\n",
       "      <td>48.488</td>\n",
       "      <td>483.0</td>\n",
       "      <td>1</td>\n",
       "      <td>476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12798</th>\n",
       "      <td>0.002716</td>\n",
       "      <td>47.552</td>\n",
       "      <td>476.0</td>\n",
       "      <td>1</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12799</th>\n",
       "      <td>0.009504</td>\n",
       "      <td>46.418</td>\n",
       "      <td>457.0</td>\n",
       "      <td>1</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12800</th>\n",
       "      <td>0.008147</td>\n",
       "      <td>45.302</td>\n",
       "      <td>431.0</td>\n",
       "      <td>1</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12801</th>\n",
       "      <td>0.002716</td>\n",
       "      <td>44.168</td>\n",
       "      <td>405.0</td>\n",
       "      <td>1</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12802</th>\n",
       "      <td>0.012220</td>\n",
       "      <td>43.772</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12803</th>\n",
       "      <td>0.010862</td>\n",
       "      <td>43.376</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12804</th>\n",
       "      <td>0.008147</td>\n",
       "      <td>42.980</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>322.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12805</th>\n",
       "      <td>0.008147</td>\n",
       "      <td>43.376</td>\n",
       "      <td>322.0</td>\n",
       "      <td>1</td>\n",
       "      <td>306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12806</th>\n",
       "      <td>0.010862</td>\n",
       "      <td>43.754</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1</td>\n",
       "      <td>292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12807</th>\n",
       "      <td>0.009504</td>\n",
       "      <td>44.150</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12808</th>\n",
       "      <td>0.012220</td>\n",
       "      <td>46.670</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1</td>\n",
       "      <td>270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12809</th>\n",
       "      <td>0.023082</td>\n",
       "      <td>49.208</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12810</th>\n",
       "      <td>0.012220</td>\n",
       "      <td>51.728</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12811</th>\n",
       "      <td>0.009504</td>\n",
       "      <td>52.826</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1</td>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12812</th>\n",
       "      <td>0.013578</td>\n",
       "      <td>53.924</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12813</th>\n",
       "      <td>0.008147</td>\n",
       "      <td>55.022</td>\n",
       "      <td>235.0</td>\n",
       "      <td>0</td>\n",
       "      <td>226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12814</th>\n",
       "      <td>0.008147</td>\n",
       "      <td>55.184</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12815</th>\n",
       "      <td>0.004073</td>\n",
       "      <td>55.328</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12816</th>\n",
       "      <td>0.000682</td>\n",
       "      <td>55.490</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12817</th>\n",
       "      <td>0.001267</td>\n",
       "      <td>52.970</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precipitation  Temperature  Outflow  ExtremeOrNot  Outflow(t+1)\n",
       "12782       0.044870       43.592    353.0             1         363.0\n",
       "12783       0.025426       43.466    363.0             1         364.0\n",
       "12784       0.004487       45.266    364.0             1         355.0\n",
       "12785       0.008974       47.048    355.0             1         340.0\n",
       "12786       0.017948       48.848    340.0             1         330.0\n",
       "12787       0.013461       50.396    330.0             1         335.0\n",
       "12788       0.010470       51.944    335.0             1         350.0\n",
       "12789       0.113671       53.492    350.0             1         368.0\n",
       "12790       0.020939       53.690    368.0             1         384.0\n",
       "12791       0.016452       53.888    384.0             1         396.0\n",
       "12792       0.013578       54.104    396.0             1         407.0\n",
       "12793       0.047522       52.862    407.0             1         424.0\n",
       "12794       0.063815       51.602    424.0             1         449.0\n",
       "12795       0.069246       50.360    449.0             1         472.0\n",
       "12796       0.043448       49.424    472.0             1         483.0\n",
       "12797       0.012220       48.488    483.0             1         476.0\n",
       "12798       0.002716       47.552    476.0             1         457.0\n",
       "12799       0.009504       46.418    457.0             1         431.0\n",
       "12800       0.008147       45.302    431.0             1         405.0\n",
       "12801       0.002716       44.168    405.0             1         381.0\n",
       "12802       0.012220       43.772    381.0             1         360.0\n",
       "12803       0.010862       43.376    360.0             1         340.0\n",
       "12804       0.008147       42.980    340.0             1         322.0\n",
       "12805       0.008147       43.376    322.0             1         306.0\n",
       "12806       0.010862       43.754    306.0             1         292.0\n",
       "12807       0.009504       44.150    292.0             1         280.0\n",
       "12808       0.012220       46.670    280.0             1         270.0\n",
       "12809       0.023082       49.208    270.0             1         261.0\n",
       "12810       0.012220       51.728    261.0             1         252.0\n",
       "12811       0.009504       52.826    252.0             1         244.0\n",
       "12812       0.013578       53.924    244.0             0         235.0\n",
       "12813       0.008147       55.022    235.0             0         226.0\n",
       "12814       0.008147       55.184    226.0             0         216.0\n",
       "12815       0.004073       55.328    216.0             0         207.0\n",
       "12816       0.000682       55.490    207.0             0         197.0\n",
       "12817       0.001267       52.970    197.0             0         187.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[12782:12818]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label of network for discriminator network\n",
    "labels_discriminator = [\"ExtremeOrNot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max scalr normalizing\n",
    "xtrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "xtest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to shift the time_series data for getting labels\n",
    "def lag_seq(df, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        df['Outflow(t+%d)' %(i+1)] = new_df['Outflow'].shift(-(i+1))\n",
    "    return df\n",
    "\n",
    "#calling function to create lag dataframe\n",
    "lag_df = lag_seq(new_df, 1)\n",
    "lag_df.dropna(inplace=True)\n",
    "\n",
    "#Splitting training and test data\n",
    "df_train, df_test = train_test_split(lag_df, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "x_train = df_train.loc[:,train_cols].values\n",
    "y_train = df_train.loc[:,label_cols].values\n",
    "y_train_dis = df_train.loc[:,labels_discriminator].values  #for discriminator\n",
    "x_test = df_test.loc[:,train_cols].values\n",
    "y_test = df_test.loc[:,label_cols].values \n",
    "y_test_dis = df_test.loc[:,labels_discriminator].values    #for discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building timeseries data with given timesteps\n",
    "def timeseries(X, Y, Y_actual, time_steps, out_steps):\n",
    "    input_size_0 = X.shape[0] - time_steps\n",
    "    input_size_1 = X.shape[1]\n",
    "    X_values = np.zeros((input_size_0, time_steps, input_size_1))\n",
    "    Y_values = np.zeros((input_size_0,))\n",
    "    Y_values_actual = np.zeros((input_size_0,))\n",
    "    \n",
    "    for i in tqdm_notebook(range(input_size_0)):\n",
    "        X_values[i] = X[i:time_steps+i]\n",
    "        Y_values[i] = Y[time_steps+i-1, 0]\n",
    "        Y_values_actual[i] = Y_actual[time_steps+i-1, 0]\n",
    "        \n",
    "    print(\"length of time-series i/o\",X_values.shape,Y_values.shape)\n",
    "    return X_values, Y_values, Y_values_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mse for train set that are greater than threshold\n",
    "threshold = 250\n",
    "timesteps = 18\n",
    "train_values_above_thres = []\n",
    "train_labels_above_theres = []\n",
    "\n",
    "for i in range(timesteps, x_train.shape[0]):\n",
    "    if (y_train[i] > threshold):\n",
    "        train_values_above_thres.append(x_train[i-timesteps:i])\n",
    "        train_labels_above_theres.append(y_train[i]) \n",
    "        \n",
    "X_train_abv_thres = np.array(train_values_above_thres)\n",
    "Y_train_abv_thres = np.array(train_labels_above_theres)\n",
    "\n",
    "tsamples, ta, tb = X_train_abv_thres.shape\n",
    "x_train_for_normalization = X_train_abv_thres.reshape((tsamples,ta*tb)) # since normalization requires 2d array\n",
    "x_train_for_normalization.shape\n",
    "\n",
    "X_Train_abv_thres = xtrain_min_max_scaler.fit_transform(x_train_for_normalization)\n",
    "Y_Train_abv_thres = ytrain_min_max_scaler.fit_transform(Y_train_abv_thres)\n",
    "\n",
    "X_Train_abv_thres = X_Train_abv_thres.reshape((tsamples, ta, tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mse for test set that are greater than threshold\n",
    "test_values_above_thres = []\n",
    "test_labels_above_theres = []\n",
    "\n",
    "for i in range(timesteps, x_test.shape[0]):\n",
    "    if (y_test[i] > threshold):\n",
    "        test_values_above_thres.append(x_test[i-timesteps:i])\n",
    "        test_labels_above_theres.append(y_test[i]) \n",
    "        \n",
    "X_test_abv_thres = np.array(test_values_above_thres)\n",
    "Y_test_abv_thres = np.array(test_labels_above_theres)\n",
    "\n",
    "tsamples, ta, tb = X_test_abv_thres.shape\n",
    "x_test_for_normalization = X_test_abv_thres.reshape((tsamples,ta*tb)) # since normalization requires 2d array\n",
    "x_test_for_normalization.shape\n",
    "\n",
    "X_Test_abv_thres = xtest_min_max_scaler.fit_transform(x_test_for_normalization)\n",
    "Y_Test_abv_thres = ytest_min_max_scaler.fit_transform(Y_test_abv_thres)\n",
    "\n",
    "X_Test_abv_thres = X_Test_abv_thres.reshape((tsamples, ta, tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(x_train, y_train, x_test, y_test): \n",
    "   \n",
    "    #Normalizing training data\n",
    "    x_train_nor = xtrain_min_max_scaler.fit_transform(x_train)\n",
    "    y_train_nor = ytrain_min_max_scaler.fit_transform(y_train)\n",
    "\n",
    "    # Normalizing test data\n",
    "    x_test_nor = xtest_min_max_scaler.fit_transform(x_test)\n",
    "    y_test_nor = ytest_min_max_scaler.fit_transform(y_test)\n",
    "    \n",
    "    # Saving actual train and test y_label\n",
    "    y_train_actual = y_train\n",
    "    y_test_actual = y_test\n",
    "    \n",
    "    #Building timeseries\n",
    "    X_Train, Y_Train, Y_train_actual = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=18, out_steps=1)\n",
    "    X_Test, Y_Test, Y_test_actual = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=18, out_steps=1)\n",
    "    \n",
    "    return X_Train, Y_Train, Y_train_actual, X_Test, Y_Test, Y_test_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f738810837cb4178847cbd9e036a46d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148416, 18, 3) (148416,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4fdcc7a70b4915b1ae641f5e90b5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37091.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37091, 18, 3) (37091,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bidur/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d482024fa4641c185258ab869f43f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=148416.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (148416, 18, 3) (148416,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12667f7466c46c8b9f21ed6e5955ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37091.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "length of time-series i/o (37091, 18, 3) (37091,)\n"
     ]
    }
   ],
   "source": [
    "#calling function to create lag dataframe\n",
    "X_Train, Y_Train, Y_train_actual, X_Test, Y_Test, Y_test_actual = data_processing(x_train, y_train, x_test, y_test)\n",
    "#calling function to create lag dataframe for distinguisher network\n",
    "X_Train_dis, Y_Train_dis, Y_train_actual_dis, X_Test_dis, Y_Test_dis, Y_test_actual_dis = data_processing(x_train, \n",
    "                                                                                                          y_train_dis, \n",
    "                                                                                                          x_test, \n",
    "                                                                                                          y_test_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Train_dis[12782:12800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network 1 for normal values\n",
    "def make_model(X_Train):\n",
    "    inp = Input(shape=(X_Train.shape[1], X_Train.shape[2]))\n",
    "    #build modelA\n",
    "    lstm1 = LSTM(units=16, return_sequences=True, \n",
    "                   name = 'lstm1A')(inp)\n",
    "#     do1A = Dropout(0.2, name = 'do1A')(lstm1A)\n",
    "    lstm2 = LSTM(units=32, return_sequences=True,\n",
    "                  name = 'lstm2A')(lstm1)\n",
    "#     do2A = Dropout(0.2, name = 'do2A')(lstm2A)\n",
    "    lstm3 = LSTM(units=64, name = 'lstm3A')(lstm2)\n",
    "#     do3A = Dropout(0.2, name = 'do3A')(lstm3A)\n",
    "    \n",
    "    dense1 = Dense(128, activation='relu')(lstm3)\n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    output_layer = Dense(1, activation='linear')(dense2)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=output_layer)\n",
    "\n",
    "#Network 2 for extreme values\n",
    "def make_model1(X_Train):\n",
    "    inp = Input(shape=(X_Train.shape[1], X_Train.shape[2]))\n",
    "    #build modelA\n",
    "    lstm1 = LSTM(units=16, return_sequences=True, \n",
    "                   name = 'lstm1A')(inp)\n",
    "#     do1A = Dropout(0.2, name = 'do1A')(lstm1A)\n",
    "    lstm2 = LSTM(units=32, return_sequences=True,\n",
    "                  name = 'lstm2A')(lstm1)\n",
    "#     do2A = Dropout(0.2, name = 'do2A')(lstm2A)\n",
    "    lstm3 = LSTM(units=64, name = 'lstm3A')(lstm2)\n",
    "#     do3A = Dropout(0.2, name = 'do3A')(lstm3A)\n",
    "    \n",
    "    dense1 = Dense(128, activation='relu')(lstm3)\n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    output_layer = Dense(1, activation='linear')(dense2)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=output_layer)\n",
    "\n",
    "#Network 3 for distinguishing which network's output to be used\n",
    "def make_model2(X_Train):\n",
    "    inp = Input(shape=(X_Train.shape[1], X_Train.shape[2]))\n",
    "    #build modelA\n",
    "    lstm1 = LSTM(units=16, return_sequences=True, \n",
    "                   name = 'lstm1A')(inp)\n",
    "#     do1A = Dropout(0.2, name = 'do1A')(lstm1A)\n",
    "    lstm2 = LSTM(units=32, return_sequences=True,\n",
    "                  name = 'lstm2A')(lstm1)\n",
    "#     do2A = Dropout(0.2, name = 'do2A')(lstm2A)\n",
    "    lstm3 = LSTM(units=64, name = 'lstm3A')(lstm2)\n",
    "#     do3A = Dropout(0.2, name = 'do3A')(lstm3A)\n",
    "    \n",
    "    dense1 = Dense(128, activation='relu')(lstm3)\n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    output_layer = Dense(2, activation='softmax')(dense2)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 67s 14ms/step - loss: 1.7585e-04 - val_loss: 2.7560e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 57s 12ms/step - loss: 9.5471e-06 - val_loss: 2.2305e-06\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 57s 12ms/step - loss: 3.4318e-06 - val_loss: 3.3056e-06\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 58s 13ms/step - loss: 4.2088e-06 - val_loss: 9.3473e-07\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 69s 15ms/step - loss: 3.2977e-06 - val_loss: 9.7370e-07\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 69s 15ms/step - loss: 1.7979e-06 - val_loss: 2.3468e-05\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 69s 15ms/step - loss: 3.2687e-06 - val_loss: 7.4127e-06\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 74s 16ms/step - loss: 2.4384e-06 - val_loss: 1.1747e-06\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 68s 15ms/step - loss: 1.9321e-06 - val_loss: 8.6091e-07\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 75s 16ms/step - loss: 1.8451e-06 - val_loss: 2.8674e-06\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1618853771.0675304\n",
      "Completing time: 1618854443.0127175\n",
      "It took -11.199086451530457 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "# Network1 Training\n",
    "mse_for_iter = []\n",
    "train_loss_over_epoch = []\n",
    "val_loss_over_epoch = []\n",
    "predicted_y_values_unnors = []\n",
    "models = []\n",
    "def run_iteration(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model = make_model(X_Train)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model.fit(X_Train, Y_Train, epochs=epochs,\n",
    "                       validation_data=(X_Test, Y_Test))\n",
    "        train_loss_over_epoch.append(history.history['loss'])\n",
    "        val_loss_over_epoch.append(history.history['val_loss'])\n",
    "        predicted_y_values = model.predict(X_Test)\n",
    "        predicted_y_values_unnor = ytrain_min_max_scaler.inverse_transform(predicted_y_values)\n",
    "        mse_for_iter.append(mean_squared_error(predicted_y_values_unnor, Y_test_actual))\n",
    "        predicted_y_values_unnors.append(predicted_y_values_unnor)\n",
    "        models.append(model)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values_unnor, model\n",
    "\n",
    "predicted_y_values_unnor, model = run_iteration(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "53/53 [==============================] - 6s 34ms/step - loss: 0.0178 - val_loss: 0.0196\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.0064 - val_loss: 0.0094\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.0054 - val_loss: 0.0071\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0036 - val_loss: 0.0061\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.0035 - val_loss: 0.0049\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 1s 17ms/step - loss: 0.0015 - val_loss: 0.0025\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1618857258.7989726\n",
      "Completing time: 1618857278.8288455\n",
      "It took -0.3338312149047852 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "# Network2 Training\n",
    "mse_for_iter1 = []\n",
    "train_loss_over_epoch1 = []\n",
    "val_loss_over_epoch1 = []\n",
    "predicted_y_values_unnors1 = []\n",
    "models1 = []\n",
    "def run_iteration1(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model1 = make_model1(X_Train_abv_thres)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model1.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "        history = model1.fit(X_Train_abv_thres, Y_Train_abv_thres, epochs=epochs,\n",
    "                       validation_data=(X_Test_abv_thres, Y_Test_abv_thres))\n",
    "        train_loss_over_epoch1.append(history.history['loss'])\n",
    "        val_loss_over_epoch1.append(history.history['val_loss'])\n",
    "        predicted_y_values1 = model1.predict(X_Test)\n",
    "        predicted_y_values_unnor1 = ytrain_min_max_scaler.inverse_transform(predicted_y_values1)\n",
    "        mse_for_iter1.append(mean_squared_error(predicted_y_values_unnor1, Y_test_actual))\n",
    "        predicted_y_values_unnors1.append(predicted_y_values_unnor1)\n",
    "        models1.append(model1)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return predicted_y_values_unnor1, model1\n",
    "\n",
    "predicted_y_values_unnor1, model1 = run_iteration1(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Epoch 1/10\n",
      "4638/4638 [==============================] - 78s 16ms/step - loss: 2.1211e-04 - val_loss: 1.7125e-05\n",
      "Epoch 2/10\n",
      "4638/4638 [==============================] - 72s 15ms/step - loss: 1.9232e-05 - val_loss: 6.9566e-06\n",
      "Epoch 3/10\n",
      "4638/4638 [==============================] - 71s 15ms/step - loss: 6.1611e-06 - val_loss: 1.8481e-06\n",
      "Epoch 4/10\n",
      "4638/4638 [==============================] - 74s 16ms/step - loss: 4.1932e-06 - val_loss: 3.2517e-06\n",
      "Epoch 5/10\n",
      "4638/4638 [==============================] - 76s 16ms/step - loss: 3.9632e-06 - val_loss: 1.4374e-05\n",
      "Epoch 6/10\n",
      "4638/4638 [==============================] - 71s 15ms/step - loss: 3.4852e-06 - val_loss: 1.0502e-06\n",
      "Epoch 7/10\n",
      "4638/4638 [==============================] - 74s 16ms/step - loss: 3.4349e-06 - val_loss: 1.7453e-06\n",
      "Epoch 8/10\n",
      "4638/4638 [==============================] - 72s 15ms/step - loss: 2.1856e-06 - val_loss: 1.6455e-06\n",
      "Epoch 9/10\n",
      "4638/4638 [==============================] - 59s 13ms/step - loss: 2.5286e-06 - val_loss: 6.4168e-07\n",
      "Epoch 10/10\n",
      "4638/4638 [==============================] - 58s 13ms/step - loss: 1.9003e-06 - val_loss: 1.5189e-06\n",
      "--------------------------\n",
      "\n",
      "Starting time: 1618854459.3437266\n",
      "Completing time: 1618855170.1487947\n",
      "It took -11.84675113360087 minutes to train the model for 1 iterations\n"
     ]
    }
   ],
   "source": [
    "# Network3 Training\n",
    "# mse_for_iter2 = []\n",
    "train_loss_over_epoch2 = []\n",
    "val_loss_over_epoch2 = []\n",
    "predicted_y_values_unnors2 = []\n",
    "models2 = []\n",
    "def run_iteration2(no_iter=20, epochs = 10):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(no_iter):\n",
    "        print(f'Iteration: {iteration + 1}')\n",
    "        K.clear_session()\n",
    "        model2 = make_model2(X_Train)\n",
    "        #plot_model(model, show_shapes=True)\n",
    "        model2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
    "        history = model2.fit(X_Train, Y_Train_dis, epochs=epochs,\n",
    "                       validation_data=(X_Test, Y_Test_dis))\n",
    "        train_loss_over_epoch2.append(history.history['loss'])\n",
    "        val_loss_over_epoch2.append(history.history['val_loss'])\n",
    "        predicted_y_values2 = model.predict(X_Test)\n",
    "#         predicted_y_values_unnor2 = ytrain_min_max_scaler.inverse_transform(predicted_y_values2)\n",
    "#         mse_for_iter2.append(mean_squared_error(predicted_y_values_unnor, Y_test_actual))\n",
    "        actual_values = np.argmax(predicted_test_values2, axis = 1)\n",
    "        predicted_y_values_unnors.append(actual_values)\n",
    "        models2.append(model2)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print('--------------------------\\n')\n",
    "    print(f'Starting time: {start_time}')\n",
    "    print(f'Completing time: {end_time}')\n",
    "    print(f'It took {(start_time - end_time)/60} minutes to train the model for {no_iter} iterations')\n",
    "    #return predicted unnormalized values for test set from last iteration \n",
    "    return actual_values, model2\n",
    "\n",
    "actual_values, model = run_iteration(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37091, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37091, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_values_unnor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00073054],\n",
       "       [0.00073067],\n",
       "       [0.00072959],\n",
       "       ...,\n",
       "       [0.01576436],\n",
       "       [0.01422025],\n",
       "       [0.0155712 ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_values_unnor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "resul_df = pd.DataFrame(predicted_y_values_unnor, columns=['Network1'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "> 1 ndim Categorical are not supported at this time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    677\u001b[0m         codes, uniques = _factorize_array(\n\u001b[0;32m--> 678\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_factorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    500\u001b[0m     uniques, codes = table.factorize(\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     )\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b553368866fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_y_values_unnor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_y_values_unnor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m  \u001b[0;31m# noqa:F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mdata_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   5609\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5611\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5612\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5613\u001b[0m             \u001b[0mindex_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mfrom_arrays\u001b[0;34m(cls, arrays, sortorder, names)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all arrays must be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactorize_from_iterables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mfactorize_from_iterables\u001b[0;34m(iterables)\u001b[0m\n\u001b[1;32m   2723\u001b[0m         \u001b[0;31m# For consistency, it should return a list of 2 lists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactorize_from_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2723\u001b[0m         \u001b[0;31m# For consistency, it should return a list of 2 lists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2724\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2725\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactorize_from_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mfactorize_from_iterable\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   2695\u001b[0m         \u001b[0;31m# but only the resulting categories, the order of which is independent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m         \u001b[0;31m# from ordered. Set ordered to False as default. See GH #15457\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m         \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 raise NotImplementedError(\n\u001b[1;32m    358\u001b[0m                     \u001b[0;34m\"> 1 ndim Categorical are not supported at this time\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                 ) from err\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# we're inferring from values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: > 1 ndim Categorical are not supported at this time"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(columns=[predicted_y_values_unnor, predicted_y_values_unnor1, actual_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
