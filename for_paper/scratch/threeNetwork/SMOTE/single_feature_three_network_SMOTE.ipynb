{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080bb524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras import backend as K \n",
    "from keras.engine.training import Model\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Dropout, Activation, Flatten\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb27b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Outflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.992</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.790</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.588</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.404</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/1980</td>\n",
       "      <td>1980</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.172</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dates  Year  Month  Day    Hours  Precipitation  Temperature  Outflow\n",
       "0  10/1/1980  1980     10    1  0:00:00            0.0      102.992      5.0\n",
       "1  10/1/1980  1980     10    1  1:00:00            0.0       97.790      5.0\n",
       "2  10/1/1980  1980     10    1  2:00:00            0.0       92.588      5.0\n",
       "3  10/1/1980  1980     10    1  3:00:00            0.0       87.404      5.0\n",
       "4  10/1/1980  1980     10    1  4:00:00            0.0       85.172      5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('./Sub0-RAW.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d445b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define train and label column\n",
    "train_cols = [\"Outflow\"]\n",
    "label_cols = [\"Outflow(t+1)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8f6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the columns that are used for training and testing\n",
    "filtered_df = df.filter([\"Precipitation\",\"Temperature\",\"Outflow\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506dfa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To convert from hourly data to daily data\n",
    "oflow = filtered_df['Outflow'].tolist()\n",
    "tem = filtered_df['Temperature'].tolist()\n",
    "precp = filtered_df['Precipitation'].tolist()\n",
    "\n",
    "#Summing up the outflow data\n",
    "lengthOfData = len(oflow)\n",
    "\n",
    "#summing 24 hours outflow\n",
    "totalOutflow = []\n",
    "for i in range(0, lengthOfData, 24):\n",
    "  totalOutflow.append(sum(oflow[i:i+24]))\n",
    "\n",
    "#averaging 24 hours temperature\n",
    "averageTemperature = []\n",
    "for i in range(0, lengthOfData, 24):\n",
    "  averageTemperature.append((sum(tem[i:i+24]))/24)\n",
    "\n",
    "#summing 24 hours precipitation\n",
    "totalPrecipitation = []\n",
    "for i in range(0, lengthOfData, 24):\n",
    "  totalPrecipitation.append(sum(precp[i:i+24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ceaff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataframe for daily data\n",
    "new_df = pd.DataFrame({'Precipitation': totalPrecipitation, 'Temperature': averageTemperature, \n",
    "                       'Outflow': totalOutflow}, columns=['Precipitation', 'Temperature', 'Outflow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aaeb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['ExtremeOrNot'] = np.where(new_df['Outflow'] > 5000, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68010a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe for network 1 without extreme values\n",
    "df_net1 = new_df[new_df['Outflow'] <= 5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e854a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label of network for discriminator network\n",
    "labels_discriminator = [\"ExtremeOrNot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6d477a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min Max scalar normalizing\n",
    "xtrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytrain_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "xtest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "ytest_min_max_scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "#Min Max scalar normalizing for extreme values\n",
    "xtrain_min_max_scaler_ext = MinMaxScaler(feature_range = (0, 1))\n",
    "ytrain_min_max_scaler_ext = MinMaxScaler(feature_range = (0, 1))\n",
    "xtest_min_max_scaler_ext = MinMaxScaler(feature_range = (0, 1))\n",
    "ytest_min_max_scaler_ext = MinMaxScaler(feature_range = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ee84bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bidurbhurtel/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/bidurbhurtel/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "#function to shift the time_series data for getting labels\n",
    "def lag_seq(df, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        df['Outflow(t+%d)' %(i+1)] = new_df['Outflow'].shift(-(i+1))\n",
    "    return df\n",
    "\n",
    "#calling function to create lag dataframe for network 3\n",
    "lag_df = lag_seq(new_df, 1)\n",
    "lag_df.dropna(inplace=True)\n",
    "\n",
    "#calling function to create lag dataframe for network 1\n",
    "lag_df_net1 = lag_seq(df_net1, 1)\n",
    "lag_df_net1.dropna(inplace=True)\n",
    "\n",
    "#Splitting training and test data for network 3\n",
    "df_train, df_test = train_test_split(lag_df, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "#splitting training and test data for network 1\n",
    "df_train_net1, df_test_net1 = train_test_split(lag_df_net1, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "# train data for network1\n",
    "x_train1 = df_train_net1.loc[:,train_cols].values\n",
    "y_train1 = df_train_net1.loc[:,label_cols].values\n",
    "#train for network3\n",
    "x_train3 = df_train.loc[:,train_cols].values\n",
    "y_train3 = df_train.loc[:,labels_discriminator].values  #for discriminator\n",
    "#test data for network 1\n",
    "x_test1 = df_test_net1.loc[:,train_cols].values\n",
    "y_test1 = df_test_net1.loc[:,label_cols].values \n",
    "#test data for network3\n",
    "x_test3 = df_test.loc[:,train_cols].values\n",
    "y_test3 = df_test.loc[:,labels_discriminator].values    #for discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b9f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building timeseries data with given timesteps\n",
    "def timeseries(X, Y, Y_actual, time_steps, out_steps):\n",
    "    input_size_0 = X.shape[0] - time_steps\n",
    "    input_size_1 = X.shape[1]\n",
    "    X_values = np.zeros((input_size_0, time_steps, input_size_1))\n",
    "    Y_values = np.zeros((input_size_0,))\n",
    "    Y_values_actual = np.zeros((input_size_0,))\n",
    "    \n",
    "    for i in tqdm_notebook(range(input_size_0)):\n",
    "        X_values[i] = X[i:time_steps+i]\n",
    "        Y_values[i] = Y[time_steps+i-1, 0]\n",
    "        Y_values_actual[i] = Y_actual[time_steps+i-1, 0]\n",
    "        \n",
    "    print(\"length of time-series i/o\",X_values.shape,Y_values.shape)\n",
    "    return X_values, Y_values, Y_values_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6d778ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mse for train set that are greater than threshold\n",
    "x_train = df_train.loc[:,train_cols].values\n",
    "y_train = df_train.loc[:,label_cols].values\n",
    "x_test = df_test.loc[:,train_cols].values\n",
    "y_test = df_test.loc[:,label_cols].values\n",
    "\n",
    "threshold = 5000\n",
    "timesteps = 18\n",
    "train_values_above_thres = []\n",
    "train_labels_above_theres = []\n",
    "\n",
    "for i in range(timesteps, x_train.shape[0]):\n",
    "    if (y_train[i] > threshold):\n",
    "        train_values_above_thres.append(x_train[i-timesteps:i])\n",
    "        train_labels_above_theres.append(y_train[i]) \n",
    "        \n",
    "X_train_abv_thres = np.array(train_values_above_thres)\n",
    "Y_train_abv_thres = np.array(train_labels_above_theres)\n",
    "\n",
    "tsamples, ta, tb = X_train_abv_thres.shape\n",
    "x_train_for_normalization = X_train_abv_thres.reshape((tsamples,ta*tb)) # since normalization requires 2d array\n",
    "x_train_for_normalization.shape\n",
    "\n",
    "X_Train_abv_thres = xtrain_min_max_scaler_ext.fit_transform(x_train_for_normalization)\n",
    "Y_Train_abv_thres = ytrain_min_max_scaler_ext.fit_transform(Y_train_abv_thres)\n",
    "\n",
    "X_Train_abv_thres = X_Train_abv_thres.reshape((tsamples, ta, tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "196cd720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking mse for test set that are greater than threshold\n",
    "test_values_above_thres = []\n",
    "test_labels_above_theres = []\n",
    "\n",
    "for i in range(timesteps, x_test.shape[0]):\n",
    "    if (y_test[i] > threshold):\n",
    "        test_values_above_thres.append(x_test[i-timesteps:i])\n",
    "        test_labels_above_theres.append(y_test[i]) \n",
    "        \n",
    "X_test_abv_thres = np.array(test_values_above_thres)\n",
    "Y_test_abv_thres = np.array(test_labels_above_theres)\n",
    "\n",
    "tsamples, ta, tb = X_test_abv_thres.shape\n",
    "x_test_for_normalization = X_test_abv_thres.reshape((tsamples,ta*tb)) # since normalization requires 2d array\n",
    "x_test_for_normalization.shape\n",
    "\n",
    "X_Test_abv_thres = xtest_min_max_scaler_ext.fit_transform(x_test_for_normalization)\n",
    "Y_Test_abv_thres = ytest_min_max_scaler_ext.fit_transform(Y_test_abv_thres)\n",
    "\n",
    "X_Test_abv_thres = X_Test_abv_thres.reshape((tsamples, ta, tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7281a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data for Network1\n",
    "def data_processing(x_train, y_train, x_test, y_test): \n",
    "   \n",
    "    #Normalizing training data\n",
    "    x_train_nor = xtrain_min_max_scaler.fit_transform(x_train)\n",
    "    y_train_nor = ytrain_min_max_scaler.fit_transform(y_train)\n",
    "\n",
    "    # Normalizing test data\n",
    "    x_test_nor = xtest_min_max_scaler.fit_transform(x_test)\n",
    "    y_test_nor = ytest_min_max_scaler.fit_transform(y_test)\n",
    "    \n",
    "    # Saving actual train and test y_label\n",
    "    y_train_actual = y_train\n",
    "    y_test_actual = y_test\n",
    "    \n",
    "    #Building timeseries\n",
    "    X_Train, Y_Train, Y_train_actual = timeseries(x_train_nor, y_train_nor, y_train_actual, time_steps=18, out_steps=1)\n",
    "    X_Test, Y_Test, Y_test_actual = timeseries(x_test_nor, y_test_nor, y_test_actual, time_steps=18, out_steps=1)\n",
    "    \n",
    "    return X_Train, Y_Train, Y_train_actual, X_Test, Y_Test, Y_test_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4b310a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for Network3\n",
    "\n",
    "#Normalizing training data\n",
    "   \n",
    "x_train_nor = xtrain_min_max_scaler.fit_transform(x_train3)\n",
    "\n",
    "# Normalizing test data\n",
    "x_test_nor = xtest_min_max_scaler.fit_transform(x_test3)\n",
    "\n",
    "#SMOTE algorithm\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_sample(x_train_nor, y_train3.ravel())\n",
    "X_test_res, y_test_res = sm.fit_sample(x_test_nor, y_test3.ravel())\n",
    "\n",
    "# Saving actual train and test y_label\n",
    "y_train_actual = y_train_res\n",
    "y_test_actual = y_test_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0c13bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6184, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c73e2585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6094"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train_res == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e62d0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 18\n",
    "input_size_0 = X_train_res.shape[0] - time_steps\n",
    "input_size_1 = X_train_res.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7d8a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values = np.zeros((input_size_0, time_steps, input_size_1))\n",
    "Y_values = np.zeros((input_size_0,))\n",
    "Y_values_actual = np.zeros((input_size_0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3f62215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bidurbhurtel/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003db7ad740c4962892830122d7c0e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12170.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(input_size_0)):\n",
    "    X_values[i] = X_train_res[i:time_steps+i]\n",
    "    Y_values[i] = y_train_res[time_steps+i-1]\n",
    "    Y_values_actual[i] = y_train_actual[time_steps+i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1217377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12170,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bc5b0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6184, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ccf674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
